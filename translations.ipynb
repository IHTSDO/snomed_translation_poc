{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40366b53-0527-4e98-848c-452c0e8a21ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# TODO\n",
    "\n",
    "- Use the preferred terms rather than the first synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c930face-aac9-4b0a-98e8-530c66b3b4de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/willh/venvs/snomed/lib/python3.10/site-packages (4.36.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: requests in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: filelock in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: deepl in /home/willh/venvs/snomed/lib/python3.10/site-packages (1.18.0)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from deepl) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests<3,>=2->deepl) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests<3,>=2->deepl) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests<3,>=2->deepl) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests<3,>=2->deepl) (3.6)\n",
      "Requirement already satisfied: tqdm in /home/willh/venvs/snomed/lib/python3.10/site-packages (4.66.1)\n",
      "Requirement already satisfied: evaluate in /home/willh/venvs/snomed/lib/python3.10/site-packages (0.4.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (2.16.1)\n",
      "Requirement already satisfied: xxhash in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (1.25.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (0.20.2)\n",
      "Requirement already satisfied: packaging in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (23.2)\n",
      "Requirement already satisfied: multiprocess in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (0.70.15)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (4.66.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (2023.10.0)\n",
      "Requirement already satisfied: pandas in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: responses<0.19 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (0.18.0)\n",
      "Requirement already satisfied: dill in /home/willh/venvs/snomed/lib/python3.10/site-packages (from evaluate) (0.3.7)\n",
      "Requirement already satisfied: filelock in /home/willh/venvs/snomed/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/willh/venvs/snomed/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (14.0.2)\n",
      "Requirement already satisfied: aiohttp in /home/willh/venvs/snomed/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2023.11.17)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /home/willh/venvs/snomed/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: Levenshtein in /home/willh/venvs/snomed/lib/python3.10/site-packages (0.25.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from Levenshtein) (3.9.3)\n",
      "Requirement already satisfied: nltk in /home/willh/venvs/snomed/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/willh/venvs/snomed/lib/python3.10/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: joblib in /home/willh/venvs/snomed/lib/python3.10/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /home/willh/venvs/snomed/lib/python3.10/site-packages (from nltk) (4.66.1)\n",
      "Requirement already satisfied: cer in /home/willh/venvs/snomed/lib/python3.10/site-packages (1.2.0)\n",
      "Requirement already satisfied: Levenshtein in /home/willh/venvs/snomed/lib/python3.10/site-packages (from cer) (0.25.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.8.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from Levenshtein->cer) (3.9.3)\n",
      "Requirement already satisfied: accelerate in /home/willh/venvs/snomed/lib/python3.10/site-packages (0.26.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from accelerate) (1.25.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: pyyaml in /home/willh/venvs/snomed/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /home/willh/venvs/snomed/lib/python3.10/site-packages (from accelerate) (0.20.2)\n",
      "Requirement already satisfied: psutil in /home/willh/venvs/snomed/lib/python3.10/site-packages (from accelerate) (5.9.7)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: filelock in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: networkx in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: sympy in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: jinja2 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: requests in /home/willh/venvs/snomed/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: wandb in /home/willh/venvs/snomed/lib/python3.10/site-packages (0.16.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (4.25.2)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (5.9.7)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (1.39.2)\n",
      "Requirement already satisfied: setuptools in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (59.6.0)\n",
      "Requirement already satisfied: PyYAML in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (3.1.41)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: setproctitle in /home/willh/venvs/snomed/lib/python3.10/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.11.17)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/willh/venvs/snomed/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install deepl\n",
    "!pip install tqdm\n",
    "!pip install evaluate\n",
    "!pip install termcolor\n",
    "!pip install Levenshtein\n",
    "!pip install nltk\n",
    "!pip install cer\n",
    "!pip install accelerate\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5667fbe-93e4-45fa-8ffb-6ab904d08771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['HF_HOME'] = '/home/ec2-user/SageMaker/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc87bd99-b973-4435-bc22-f425447347e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from snomed_graph import *\n",
    "import getpass\n",
    "import deepl\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import evaluate\n",
    "from termcolor import colored\n",
    "from collections import namedtuple\n",
    "from operator import __or__\n",
    "from functools import reduce\n",
    "from ast import literal_eval\n",
    "from Levenshtein import ratio\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "627cc59c-57ee-4d6c-85db-9a3f7a7a7805",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "AYA_CHECKPOINT = \"CohereForAI/aya-101\"\n",
    "PATH_TO_SERIALIZED_SNOMED_GRAPH = \"./data/snomed_graph/full_concept_graph.gml\"\n",
    "PATH_TO_TRANSLATION_SAMPLES = \"./data/prepared_translation_data/samples.csv\"\n",
    "PATH_TO_ALL_TRANSLATION_REFERENCES = \"./data/prepared_translation_data/all_translations.csv\"\n",
    "PATH_TO_DEEPL_TRANSLATION_RESULTS = \"./data/cache/deepl_results.json\"\n",
    "PATH_TO_AYA_VANILLA_TRANSLATION_RESULTS = \"./data/cache/aya_results_vanilla.json\"\n",
    "PATH_TO_AYA_ENRICHED_TRANSLATION_RESULTS = \"./data/cache/aya_results_enriched.json\"\n",
    "ALL_OUTPUT_PATH = \"./data/translation_outputs/all_translations.csv\"\n",
    "CT1_OUTPUT_PATH = \"./data/translation_outputs/ct1_translations.csv\"\n",
    "CT2_OUTPUT_PATH = \"./data/translation_outputs/ct2_translations.csv\"\n",
    "SIM_OUTPUT_PATH = \"./data/translation_outputs/sim_translations.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48c36229-2afa-4b82-bb1f-c6c44c31bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_case = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa931693-9d38-442f-9a31-22d7a6b4609a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "DEEPL_AUTH_KEY = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93502126-6915-4c0c-858b-eecf7620077a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "langcodes = {\n",
    "    \"Dutch\": \"NL\",\n",
    "    \"Estonian\": \"ET\",\n",
    "    \"Korean\": \"KO\",\n",
    "    \"Swedish\": \"SV\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15d61637-bd8d-4f78-984a-99fc42b96cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "important_attributes = {\n",
    "    # 'Access (attribute)',\n",
    "    # 'After (attribute)',\n",
    "    'Associated finding (attribute)',\n",
    "    'Associated morphology (attribute)',\n",
    "    'Associated procedure (attribute)',\n",
    "    'Associated with (attribute)',\n",
    "    'Before (attribute)',\n",
    "    'Causative agent (attribute)',\n",
    "    'Characterizes (attribute)',\n",
    "    # 'Clinical course (attribute)',\n",
    "    'Component (attribute)',\n",
    "    'Direct device (attribute)',\n",
    "    'Direct morphology (attribute)',\n",
    "    'Direct site (attribute)',\n",
    "    'Direct substance (attribute)',\n",
    "    'Due to (attribute)',\n",
    "    'During (attribute)',\n",
    "    # 'Finding context (attribute)',\n",
    "    'Finding informer (attribute)',\n",
    "    'Finding method (attribute)',\n",
    "    'Finding site (attribute)',\n",
    "    'Has absorbability (attribute)',\n",
    "    'Has active ingredient (attribute)',\n",
    "    'Has basic dose form (attribute)',\n",
    "    'Has basis of strength substance (attribute)',\n",
    "    'Has coating material (attribute)',\n",
    "    'Has compositional material (attribute)',\n",
    "    'Has concentration strength denominator unit (attribute)',\n",
    "    'Has concentration strength numerator unit (attribute)',\n",
    "    'Has device intended site (attribute)',\n",
    "    'Has disposition (attribute)',\n",
    "    'Has dose form administration method (attribute)',\n",
    "    'Has dose form intended site (attribute)',\n",
    "    'Has dose form release characteristic (attribute)',\n",
    "    'Has dose form transformation (attribute)',\n",
    "    'Has filling (attribute)',\n",
    "    'Has focus (attribute)',\n",
    "    'Has ingredient qualitative strength (attribute)',\n",
    "    'Has intent (attribute)',\n",
    "    # 'Has interpretation (attribute)',\n",
    "    'Has manufactured dose form (attribute)',\n",
    "    'Has precise active ingredient (attribute)',\n",
    "    'Has presentation strength denominator unit (attribute)',\n",
    "    'Has presentation strength numerator unit (attribute)',\n",
    "    'Has realization (attribute)',\n",
    "    'Has specimen (attribute)',\n",
    "    'Has state of matter (attribute)',\n",
    "    'Has surface texture (attribute)',\n",
    "    'Has target population (attribute)',\n",
    "    'Has unit of presentation (attribute)',\n",
    "    'Indirect device (attribute)',\n",
    "    'Indirect morphology (attribute)',\n",
    "    'Inherent location (attribute)',\n",
    "    'Inheres in (attribute)',\n",
    "    'Interprets (attribute)',\n",
    "    # 'Is a (attribute)',\n",
    "    'Is modification of (attribute)',\n",
    "    'Is sterile (attribute)',\n",
    "    'Laterality (attribute)',\n",
    "    'Measurement method (attribute)',\n",
    "    'Method (attribute)',\n",
    "    'Occurrence (attribute)',\n",
    "    'Pathological process (attribute)',\n",
    "    'Plays role (attribute)',\n",
    "    'Precondition (attribute)',\n",
    "    'Priority (attribute)',\n",
    "    'Procedure context (attribute)',\n",
    "    'Procedure device (attribute)',\n",
    "    'Procedure morphology (attribute)',\n",
    "    'Procedure site (attribute)',\n",
    "    'Procedure site - Direct (attribute)',\n",
    "    'Procedure site - Indirect (attribute)',\n",
    "    'Process acts on (attribute)',\n",
    "    'Process duration (attribute)',\n",
    "    'Process extends to (attribute)',\n",
    "    'Process output (attribute)',\n",
    "    'Property (attribute)',\n",
    "    'Recipient category (attribute)',\n",
    "    'Relative to (attribute)',\n",
    "    'Relative to part of (attribute)',\n",
    "    'Revision status (attribute)',\n",
    "    'Route of administration (attribute)',\n",
    "    # 'Scale type (attribute)',\n",
    "    # 'Severity (attribute)',\n",
    "    'Specimen procedure (attribute)',\n",
    "    'Specimen source identity (attribute)',\n",
    "    'Specimen source morphology (attribute)',\n",
    "    'Specimen source topography (attribute)',\n",
    "    'Specimen substance (attribute)',\n",
    "    # 'Subject relationship context (attribute)',\n",
    "    'Surgical approach (attribute)',\n",
    "    'Technique (attribute)',\n",
    "    # 'Temporal context (attribute)',\n",
    "    # 'Temporally related to (attribute)',\n",
    "    # 'Time aspect (attribute)',\n",
    "    # 'Units (attribute)',\n",
    "    'Using access device (attribute)',\n",
    "    'Using device (attribute)',\n",
    "    'Using energy (attribute)',\n",
    "    'Using substance (attribute)'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f1ac12-d370-4c13-958a-ed503cfcb007",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddf79ad-498a-49d7-8704-ea8d5dd952c5",
   "metadata": {},
   "source": [
    "## 1.1 Load the concepts to translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba0a6ccb-8e5a-4727-a45d-d8cb60cd4916",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12640"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns are: sctid, fsn, hierarchy, language, context_tier, depth_tier, translations\n",
    "all_df = (\n",
    "    pd.read_csv(PATH_TO_TRANSLATION_SAMPLES)\n",
    "    .set_index([\"sctid\", \"language\"])\n",
    ")\n",
    "\n",
    "all_df.reference_translations = all_df.reference_translations.apply(literal_eval)\n",
    "\n",
    "all_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7455e7-6667-4abd-b49e-4d5bd780a33f",
   "metadata": {},
   "source": [
    "## 1.2 Load the full set of reference translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33e90b69-f3cb-4a04-9548-5bb26c913774",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "651355"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns are: sctid, fsn, hierarchy, language, context_tier, depth_tier, translations\n",
    "ref_df = (\n",
    "    pd.read_csv(PATH_TO_ALL_TRANSLATION_REFERENCES)\n",
    "    .set_index([\"sctid\", \"language\"])\n",
    ")\n",
    "\n",
    "ref_df.translations = ref_df.translations.apply(literal_eval)\n",
    "\n",
    "ref_df = ref_df.rename(axis=\"columns\", mapper={\"translations\": \"reference_translations\"})\n",
    "\n",
    "ref_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde6e15f-15e9-4284-a4ee-e2345a80cfe3",
   "metadata": {},
   "source": [
    "## 1.3 Load the SNOMED graph object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77bb2042-56ec-40ac-9c55-cedfa18a3c85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNOMED graph has 361179 vertices and 1179749 edges\n"
     ]
    }
   ],
   "source": [
    "G = SnomedGraph.from_serialized(PATH_TO_SERIALIZED_SNOMED_GRAPH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d5d051-4705-446b-ae51-f47fb39634bf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. Evaluation Harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8907f3d-f1a3-4738-afa3-9179dd756ae0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Google BLEU\n",
    "# Max of precision, recall of all ngrams (of 1-4 tokens)\n",
    "# Higher is better\n",
    "# https://huggingface.co/spaces/evaluate-metric/google_bleu\n",
    "google_bleu = evaluate.load(\"google_bleu\")\n",
    "\n",
    "# CharacTER\n",
    "# Roughly: min # char edits required to match pred to ref, normalized by pred len\n",
    "# Lower is better\n",
    "# https://huggingface.co/spaces/evaluate-metric/character\n",
    "character = evaluate.load(\"character\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33bf8095-2b5a-4790-85fa-894daa4faa62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exact_match(predictions, references):\n",
    "    N = len(predictions)\n",
    "    n = 0\n",
    "    for p, r in zip(predictions, references):\n",
    "        if p in r:\n",
    "            n += 1\n",
    "    return {'exact_match': float(n)/N}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b778f47f-c500-4ebf-aff1-5f283165ba70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Levenshtein Ratio\n",
    "# 1 - [Levenshtein Dist] / [Sum of lengths]\n",
    "# Higher is better\n",
    "# https://rapidfuzz.github.io/Levenshtein/levenshtein.html#ratio\n",
    "def levenshtein_ratio(predictions, references):\n",
    "    ratios = [\n",
    "        np.max([ratio(p, r) for r in refs])\n",
    "        for p, refs in zip(predictions, references)\n",
    "    ]\n",
    "    return {'levenshtein_ratio': np.mean(ratios)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef54b57-bbe4-49bb-b1db-cfc2bc47e084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_translations(row_or_df, target_column, ignore_case):\n",
    "    if isinstance(row_or_df, pd.DataFrame):\n",
    "        assert target_column in row_or_df.columns    \n",
    "        candidates = list(row_or_df.to_dict()[target_column].values())\n",
    "        references = row_or_df.reference_translations.tolist()\n",
    "    else:\n",
    "        candidates = [getattr(row_or_df, target_column)]\n",
    "        references = [row_or_df.reference_translations]\n",
    "    if ignore_case:\n",
    "        candidates = [c.lower() for c in candidates]\n",
    "        references = [r.lower() for r in references]\n",
    "    results = [\n",
    "        exact_match(predictions=candidates, references=references),\n",
    "        levenshtein_ratio(predictions=candidates, references=references),\n",
    "        google_bleu.compute(predictions=candidates, references=references),\n",
    "        character.compute(predictions=candidates, references=references),\n",
    "    ]\n",
    "    results = reduce(__or__, results, dict())\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15910fa5-05da-4684-8434-6569ddc09304",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. Generate baseline translations with DeepL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4876d773-7864-4396-9418-ff7f0b9747ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "translator = deepl.Translator(DEEPL_AUTH_KEY)\n",
    "\n",
    "def translate_with_deepl(df, G):\n",
    "    \n",
    "    with open(PATH_TO_DEEPL_TRANSLATION_RESULTS, \"r\") as f:\n",
    "        deepl_results = json.load(f)\n",
    "    \n",
    "    for it, row in enumerate(tqdm(df.itertuples(), total=df.shape[0])):\n",
    "        sctid, language = row.Index\n",
    "        langcode = langcodes[language]\n",
    "        source_concept = G.get_concept_details(sctid)\n",
    "        source_preferred_term = source_concept.fsn.replace(f\"({source_concept.hierarchy})\", \"\").strip()\n",
    "        key = str(sctid) + \"_\" + language\n",
    "        try:\n",
    "            yield deepl_results[key]\n",
    "        except KeyError:\n",
    "            deepl_result = translator.translate_text(source_preferred_term, target_lang=langcode)\n",
    "            deepl_results[key] = deepl_result.text\n",
    "            yield deepl_result.text\n",
    "        if it % 100 == 0:\n",
    "            with open(PATH_TO_DEEPL_TRANSLATION_RESULTS, \"w\") as f:\n",
    "                json.dump(deepl_results, f)\n",
    "\n",
    "    with open(PATH_TO_DEEPL_TRANSLATION_RESULTS, \"w\") as f:\n",
    "        json.dump(deepl_results, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cd516d-1f59-4167-bd43-5f7949915ce3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_df[\"deepl_translation\"] = list(translate_with_deepl(all_df, G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "20e9c100-c32b-4f24-b590-5a00d75c9f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.08662974683544304,\n",
       " 'levenshtein_ratio': 0.7370298864393613,\n",
       " 'google_bleu': 0.2459922409495806,\n",
       " 'cer_score': 0.381689058931287}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_translations(all_df, \"deepl_translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b99278-9f6e-4ba4-b528-9e08c7a5c9d1",
   "metadata": {},
   "source": [
    "# 4. Generate translations using \"vanilla\" Aya model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3a6b8007-147c-4157-9109-0f752630daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(AYA_CHECKPOINT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452b68eb-dc10-498e-8f50-f7c66559ae04",
   "metadata": {},
   "source": [
    "## 4.1 Load Aya on a local machine\n",
    "\n",
    "N.B. T5-derivative models (like Aya) do not yet support FlashAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74a541c0-7c6b-49a8-b7e9-b99c88551bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76fea04679143ed8f3d9a367e320e56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "aya_model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    AYA_CHECKPOINT, \n",
    "    device_map=\"cuda\", \n",
    "    quantization_config=bnb_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd7da6-6b5e-46dc-b73a-d076dd31a51a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.2 Load Aya on a multi-GPU set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "90aff670-69e8-4d02-a9ff-ad2c5be6cb38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aya_model = AutoModelForSeq2SeqLM.from_pretrained(AYA_CHECKPOINT, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15a5cab-422c-47e3-b621-f768cfffcffd",
   "metadata": {},
   "source": [
    "## 4.3 Standard wrapper functions for processing with Aya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "563b4e79-e538-490f-b5c6-69315c275951",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aya_postprocessor(result):\n",
    "    return (\n",
    "        result\n",
    "        .replace(tokenizer.eos_token, \"\")\n",
    "        .replace(tokenizer.pad_token, \"\")\n",
    "        .replace(\".\", \"\")\n",
    "        .strip()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e947485-cfe1-4db4-ba14-abd7bfa83789",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate_with_aya(df, G, prompt_assembler, ref_df=None, results_filepath=None, rebuild=False, save=False):\n",
    "\n",
    "    if rebuild:\n",
    "        results = dict()\n",
    "    else:\n",
    "        with open(results_filepath, \"r\") as f:\n",
    "            results = json.load(f)\n",
    "    \n",
    "    for row in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "        sctid, language = row.Index\n",
    "        key = str(sctid) + \"_\" + language\n",
    "        try:\n",
    "            yield results[key]\n",
    "        except KeyError:\n",
    "            prompt = prompt_assembler(row, G, ref_df)\n",
    "            input = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "            output = aya_model.generate(input, max_new_tokens=256)\n",
    "            result = tokenizer.decode(output[0])\n",
    "            result = aya_postprocessor(result)\n",
    "            results[key] = result\n",
    "            yield result\n",
    "\n",
    "    if save:\n",
    "        with open(results_filepath, \"w\") as f:\n",
    "            json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed01d46-55ec-4412-b07f-bf2455c6f99d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4.4 Test Aya with a few translations into English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb03ba59-614f-4c2f-91ca-d0b3ef930c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_translate_with_aya(df, G):\n",
    "    for row in tqdm(df.itertuples(), total=df.shape[0]):\n",
    "        sctid, language = row.Index\n",
    "        preferred_term = row.reference_translations[0]\n",
    "        reference_translations = G.get_concept_details(sctid).synonyms\n",
    "        # ICL\n",
    "        try:\n",
    "            icl_row = next(df[(df.index.get_level_values(0) != sctid) & (df.index.get_level_values(1) == language)].sample(1).itertuples())\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            icl_sctid = icl_row.Index[0]\n",
    "            icl_preferred_term = icl_row.reference_translations[0]\n",
    "            icl_reference_translations = G.get_concept_details(icl_sctid).synonyms\n",
    "            # construct prompt\n",
    "            prompt_template = 'Translate the following clinical concept into English: \"{{PREFERRED_TERM}}\". {{TRANSLATED_TERM}}.\\n'\n",
    "            prompt = (\n",
    "                prompt_template.replace(\"{{PREFERRED_TERM}}\", icl_preferred_term).replace(\"{{TRANSLATED_TERM}}\", icl_reference_translations[0]) +\n",
    "                prompt_template.replace(\"{{PREFERRED_TERM}}\", preferred_term).replace(\"{{TRANSLATED_TERM}}.\\n\", \"\")\n",
    "            )\n",
    "            print(prompt)\n",
    "            input = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "            output = aya_model.generate(input, max_new_tokens=256)\n",
    "            result = tokenizer.decode(output[0])\n",
    "            result = aya_postprocessor(result)\n",
    "            \n",
    "            print(\n",
    "                colored(\"\\nSCTID: \", \"red\", attrs=['bold']),\n",
    "                sctid,\n",
    "                colored(\"\\nSource Language: \", \"red\", attrs=['bold']),\n",
    "                language,\n",
    "                colored(\"\\nPreferred Term: \", \"red\", attrs=['bold']),\n",
    "                preferred_term,\n",
    "                colored(\"\\nReference Translations: \", \"red\", attrs=['bold']),\n",
    "                reference_translations,\n",
    "                colored(\"\\nAya Translation: \", \"red\", attrs=['bold']),            \n",
    "                result,\n",
    "                \"\\n\\n\",\n",
    "                # colored(\"\\nAya Scores: \", \"red\", attrs=['bold']),\n",
    "                # \", \".join([k+\": \"+str(v) for k,v in scores.items()]),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6548608a-21a8-4b91-a26e-73915f49627c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "502a14e686794e1a844a25be115b05e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following clinical concept into English: \"Kartsinomatoos\". Carcinomatosis.\n",
      "Translate the following clinical concept into English: \"Briljantroheline\". \n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 396057002 \u001b[1m\u001b[31m\n",
      "Source Language: \u001b[0m Estonian \u001b[1m\u001b[31m\n",
      "Preferred Term: \u001b[0m Briljantroheline \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Brilliant green'] \u001b[1m\u001b[31m\n",
      "Aya Translation: \u001b[0m Brillant green \n",
      "\n",
      "\n",
      "Translate the following clinical concept into English: \"beriberi bij zuigeling\". Infantile beriberi.\n",
      "Translate the following clinical concept into English: \"structuur van iliacale arterie en/of femorale arterie\". \n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 299716001 \u001b[1m\u001b[31m\n",
      "Source Language: \u001b[0m Dutch \u001b[1m\u001b[31m\n",
      "Preferred Term: \u001b[0m structuur van iliacale arterie en/of femorale arterie \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Iliac and femoral artery structures', 'Iliac and/or femoral artery structures'] \u001b[1m\u001b[31m\n",
      "Aya Translation: \u001b[0m Iliac and/or femoral arteries \n",
      "\n",
      "\n",
      "Translate the following clinical concept into English: \"structuur van iliacale arterie en/of femorale arterie\". Iliac and femoral artery structures.\n",
      "Translate the following clinical concept into English: \"structuur van pars lateralis van os occipitale\". \n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 64312005 \u001b[1m\u001b[31m\n",
      "Source Language: \u001b[0m Dutch \u001b[1m\u001b[31m\n",
      "Preferred Term: \u001b[0m structuur van pars lateralis van os occipitale \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Lateral part of occipital bone', 'Exoccipital bone', 'Structure of lateral part of occipital bone'] \u001b[1m\u001b[31m\n",
      "Aya Translation: \u001b[0m occipital fossa structures \n",
      "\n",
      "\n",
      "Translate the following clinical concept into English: \"structuur van iliacale arterie en/of femorale arterie\". Iliac and femoral artery structures.\n",
      "Translate the following clinical concept into English: \"beriberi bij zuigeling\". \n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 238126005 \u001b[1m\u001b[31m\n",
      "Source Language: \u001b[0m Dutch \u001b[1m\u001b[31m\n",
      "Preferred Term: \u001b[0m beriberi bij zuigeling \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Infantile beriberi'] \u001b[1m\u001b[31m\n",
      "Aya Translation: \u001b[0m Beriberi in infants \n",
      "\n",
      "\n",
      "Translate the following clinical concept into English: \"Avaldunud ravimi kõrvaltoime\". Medication side effects present.\n",
      "Translate the following clinical concept into English: \"Kartsinomatoos\". \n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 7010000 \u001b[1m\u001b[31m\n",
      "Source Language: \u001b[0m Estonian \u001b[1m\u001b[31m\n",
      "Preferred Term: \u001b[0m Kartsinomatoos \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Carcinomatosis'] \u001b[1m\u001b[31m\n",
      "Aya Translation: \u001b[0m Cancer \n",
      "\n",
      "\n",
      "Translate the following clinical concept into English: \"장형 샘암종\". Adenocarcinoma, intestinal type.\n",
      "Translate the following clinical concept into English: \"여성 회음 태선화\". \n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 289859002 \u001b[1m\u001b[31m\n",
      "Source Language: \u001b[0m Korean \u001b[1m\u001b[31m\n",
      "Preferred Term: \u001b[0m 여성 회음 태선화 \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Lichenification of female perineum'] \u001b[1m\u001b[31m\n",
      "Aya Translation: \u001b[0m Female genital warts \n",
      "\n",
      "\n",
      "Translate the following clinical concept into English: \"Kartsinomatoos\". Carcinomatosis.\n",
      "Translate the following clinical concept into English: \"Avaldunud ravimi kõrvaltoime\". \n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 401207004 \u001b[1m\u001b[31m\n",
      "Source Language: \u001b[0m Estonian \u001b[1m\u001b[31m\n",
      "Preferred Term: \u001b[0m Avaldunud ravimi kõrvaltoime \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Medication side effects present', 'Has shown side effects from medication', 'Medication side-effect'] \u001b[1m\u001b[31m\n",
      "Aya Translation: \u001b[0m Adverse drug reaction \n",
      "\n",
      "\n",
      "Translate the following clinical concept into English: \"여성 회음 태선화\". Lichenification of female perineum.\n",
      "Translate the following clinical concept into English: \"장형 샘암종\". \n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 25190001 \u001b[1m\u001b[31m\n",
      "Source Language: \u001b[0m Korean \u001b[1m\u001b[31m\n",
      "Preferred Term: \u001b[0m 장형 샘암종 \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Adenocarcinoma, intestinal type', 'Carcinoma, intestinal type', 'Carcinoma - intestinal type', 'Adenocarcinoma - intestinal type'] \u001b[1m\u001b[31m\n",
      "Aya Translation: \u001b[0m Large-cell breast cancer \n",
      "\n",
      "\n",
      "Translate the following clinical concept into English: \"structuur van iliacale arterie en/of femorale arterie\". Iliac and femoral artery structures.\n",
      "Translate the following clinical concept into English: \"structuur van linker nervus glossopharyngeus\". \n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 734529006 \u001b[1m\u001b[31m\n",
      "Source Language: \u001b[0m Dutch \u001b[1m\u001b[31m\n",
      "Preferred Term: \u001b[0m structuur van linker nervus glossopharyngeus \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Structure of left glossopharyngeal nerve'] \u001b[1m\u001b[31m\n",
      "Aya Translation: \u001b[0m Structuur van de linker glossopharyngeale zenuw \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_translate_with_aya(all_df.sample(10), G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c4df2e-926e-4991-bfea-48aed0886cda",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.5 Translate from English into our target languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74a2f464-b00c-4e0e-b028-be0b8aac0e6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_aya_vanilla_prompt(row, G, df):\n",
    "    sctid, language = row.Index\n",
    "    concept = G.get_concept_details(sctid)\n",
    "    preferred_term = concept.fsn.replace(f\"({concept.hierarchy})\", \"\").strip()\n",
    "    if language == \"Swedish\":\n",
    "        return f'Translate the following clinical concept into Swedish: \"Pain disorder with psychological factor\". smärtsyndrom med psykologisk faktor.\\nTranslate the following clinical concept into Swedish: \"{preferred_term}\". '\n",
    "    elif language == \"Estonian\":\n",
    "        return f'Translate the following clinical concept into Estonian: \"Osseous choristoma\". Luuline koristoom. \\nTranslate the following clinical concept into Estonian: \"{preferred_term}\". '\n",
    "    elif language == \"Korean\":\n",
    "        return f'Translate the following clinical concept into Korean: \"Endoscopic excision of lesion of esophagus\". 식도 병변 내시경 절제. \\nTranslate the following clinical concept into Korean: \"{preferred_term}\". '\n",
    "    elif language == \"Dutch\":\n",
    "        return f'Translate the following clinical concept into Dutch: \"Open repair of lumbar hernia using biological mesh\".  open hernioplastiek van hernia lumbalis met biologisch matje.\\nTranslate the following clinical concept into Dutch: \"{preferred_term}\". '\n",
    "    else:\n",
    "        raise ValueError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdc4008f-8f2c-4657-b5d3-08ba737e852b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a230dcbed784737b02d380d4e21af9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12640 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_df[\"aya_vanilla_translation\"] = list(translate_with_aya(\n",
    "    all_df, G, prepare_aya_vanilla_prompt, PATH_TO_AYA_VANILLA_TRANSLATION_RESULTS, rebuild=True, save=False\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e33d198-27a3-4ac5-a883-743e37ee6e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.03235759493670886,\n",
       " 'levenshtein_ratio': 0.608165798751417,\n",
       " 'google_bleu': 0.1350622406639004,\n",
       " 'cer_score': 0.5526435448522717}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_translations(all_df, \"aya_vanilla_translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba718b0f-1e58-44c7-86ac-587f8fd00221",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_df.to_csv(ALL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a04795-ddf7-4a49-a295-31ab317dd209",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5. Evaluate Aya with enriched prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ef7512-8caa-4ae0-abf1-51824375ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_prompt_template = \"\"\"\n",
    "You are a medical translation expert.\n",
    "Your job is to translate formal clinical terms found within the SNOMED Concept Terminology into {{TARGET_LANGUAGE}}.\n",
    "The concept you need to translate is “{{PREFERRED_TERM}}”.\n",
    "Here is some information about the concept which may help you:\n",
    "{{SYNONYMS_FRAGMENT}}\n",
    "{{HIERARCHY_FRAGMENT}}\n",
    "{{PARENTS_FRAGMENT}}\n",
    "{{RELATIONSHIPS_FRAGMENT}}\n",
    "Now, the translation of “{{PREFERRED_TERM}}” into {{TARGET_LANGUAGE}} is:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2decaf75-a82d-4176-9dea-58aca84337e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_synonyms_fragment(preferred_term, synonyms):\n",
    "    if len(synonyms) == 0:\n",
    "        return \"\"\n",
    "    else:\n",
    "        syn_str = '\"' + '\" and \"'.join(synonyms) + '\"'\n",
    "        return f'In English, synonyms for \"{preferred_term}\" include: {syn_str}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03f3b5f-3990-4b7b-8615-8fddb03181cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_hierarchy_fragment(preferred_term, hierarchy):\n",
    "    return f'\"{preferred_term}\" is a {hierarchy}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d849132e-eee2-4393-9123-a35190cd934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_parents_fragment(preferred_term, parents):\n",
    "    fragment = \"\"\n",
    "    for p in parents:\n",
    "        fragment += f'\"{preferred_term}\" is a kind of {p.synonyms[0]}.\\n'\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38742d6a-36b5-44d0-bcfb-3f4110d6f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt_relationships_fragment(preferred_term, relationship_groups):\n",
    "    fragment = \"\"\n",
    "    for g in relationship_groups:\n",
    "        for r in g.relationships:\n",
    "            type = r.type.replace(\" (attribute)\", \"\").lower()\n",
    "            tgt = r.tgt.synonyms[0]\n",
    "            fragment += f'\"{preferred_term}\" has {type} {tgt}\\n'\n",
    "    return fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c62256-eb64-4acd-9143-4ec0ce0396b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_aya_enriched_prompt(row, G, df):\n",
    "    sctid, language = row.Index\n",
    "    concept = G.get_full_concept(sctid)\n",
    "    preferred_term = concept.synonyms[0]\n",
    "    return (\n",
    "        enriched_prompt_template\n",
    "        .replace(\"{{TARGET_LANGUAGE}}\", language)\n",
    "        .replace(\"{{PREFERRED_TERM}}\", preferred_term)\n",
    "        .replace(\"{{SYNONYMS_FRAGMENT}}\", generate_prompt_synonyms_fragment(preferred_term, concept.synonyms[1:]))\n",
    "        .replace(\"{{HIERARCHY_FRAGMENT}}\", generate_prompt_hierarchy_fragment(preferred_term, concept.hierarchy))\n",
    "        .replace(\"{{PARENTS_FRAGMENT}}\", generate_prompt_parents_fragment(preferred_term, concept.parents))\n",
    "        .replace(\"{{RELATIONSHIPS_FRAGMENT}}\", generate_prompt_relationships_fragment(preferred_term, concept.inferred_relationship_groups))\n",
    "        .replace(\"\\n\\n\", \"\\n\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76fa6935-96ca-4227-99e4-ffd4682fe558",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prepare_aya_enriched_prompt(next(all_df.itertuples()), G, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03ef629-dc72-4351-abdc-41e67c5f43f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"aya_enriched_translation\"] = list(translate_with_aya(all_df, G, prepare_aya_enriched_prompt, PATH_TO_AYA_ENRICHED_TRANSLATION_RESULTS, rebuild=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c9ddee-b928-478b-a082-cb412e835826",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_translations(all_df, \"aya_enriched_translation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e09ae0a-ecf2-4ff9-a82d-dcbf8ef3c8d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6. Translate Context Tier 1 Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "811b00b4-9069-490f-866c-8b347f7b5bca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_aya_ct1_prompt(row, G, ref_df):\n",
    "    sctid, language = row.Index\n",
    "    concept = G.get_full_concept(sctid)\n",
    "    preferred_term = concept.fsn.replace(f\"({concept.hierarchy})\", \"\").strip()\n",
    "    parent_concepts = [\n",
    "        G.get_full_concept(p.sctid) for p in concept.parents\n",
    "    ]\n",
    "    parent_data = [\n",
    "        (\n",
    "            c.fsn.replace(f\"({c.hierarchy})\", \"\").strip(),\n",
    "            ref_df.loc[(c.sctid, language)].reference_translations[0],\n",
    "        )\n",
    "        for c in parent_concepts\n",
    "    ]\n",
    "    prompt_fragments = [\n",
    "        f'Translate the following clinical concept into {language}: \"{pt}\". {rt}.'\n",
    "        for pt, rt in parent_data\n",
    "    ]    \n",
    "    prompt = '\\n'.join(prompt_fragments)\n",
    "    prompt += f'\\nTranslate the following clinical concept into {language}: \"{preferred_term}\". '\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75dbd4e3-faed-41d3-a614-7720e304679f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8657"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct1_df = all_df[all_df.context_tier.isin([\"Tier 1\", \"Tier 2\"])]\n",
    "ct1_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ac818ad-5856-4732-b54f-915bd5006966",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebeb4d392d394b7bad1b6a7b06ccddcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 13\u001b[0m, in \u001b[0;36mtranslate_with_aya\u001b[0;34m(df, G, prompt_assembler, ref_df, results_filepath, rebuild, save)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '729358000_Dutch'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ct1_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maya_ct1_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtranslate_with_aya\u001b[49m\u001b[43m(\u001b[49m\u001b[43mct1_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepare_aya_ct1_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrebuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[25], line 17\u001b[0m, in \u001b[0;36mtranslate_with_aya\u001b[0;34m(df, G, prompt_assembler, ref_df, results_filepath, rebuild, save)\u001b[0m\n\u001b[1;32m     15\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt_assembler(row, G, ref_df)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43maya_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m result \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     19\u001b[0m result \u001b[38;5;241m=\u001b[39m aya_postprocessor(result)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/generation/utils.py:1718\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1702\u001b[0m         input_ids,\n\u001b[1;32m   1703\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1714\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1715\u001b[0m     )\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/generation/utils.py:2579\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2576\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2579\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2580\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2582\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2583\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2587\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1743\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1740\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1743\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1758\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1110\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1096\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1097\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         output_attentions,\n\u001b[1;32m   1108\u001b[0m     )\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1110\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:724\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    722\u001b[0m     query_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 724\u001b[0m cross_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    737\u001b[0m \u001b[38;5;66;03m# clamp inf values to enable fp16 training\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:635\u001b[0m, in \u001b[0;36mT5LayerCrossAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, query_length, output_attentions)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    624\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    632\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    633\u001b[0m ):\n\u001b[1;32m    634\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 635\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEncDecAttention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnormed_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_value_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_value_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    644\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    645\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    646\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    647\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m attention_output[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:453\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    450\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mpermute([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# shape (1, num_heads, query_length, key_length)\u001b[39;00m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    455\u001b[0m     hidden_states,\n\u001b[1;32m    456\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    457\u001b[0m     key_value_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    458\u001b[0m     position_bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    459\u001b[0m     past_key_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    460\u001b[0m     layer_head_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    461\u001b[0m     query_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    462\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    463\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    464\u001b[0m ):\n\u001b[1;32m    465\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;124;03m    Self-attention (if key_value_states is None) or attention over source sentence (provided by key_value_states).\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    468\u001b[0m     \u001b[38;5;66;03m# Input is (batch_size, seq_length, dim)\u001b[39;00m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;66;03m# Mask is (batch_size, key_length) (non-causal) or (batch_size, key_length, key_length)\u001b[39;00m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# past_key_value[0] is (batch_size, n_heads, q_len - 1, dim_per_head)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ct1_df[\"aya_ct1_translation\"] = list(translate_with_aya(ct1_df, G, prepare_aya_ct1_prompt, ref_df, None, rebuild=True, save=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc54637b-16b0-4ffe-90ec-fd3d43950b34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.13734550075083748,\n",
       " 'levenshtein_ratio': 0.728187395794738,\n",
       " 'google_bleu': 0.319951960733121,\n",
       " 'cer_score': 0.4275629513922285}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_translations(ct1_df, \"aya_ct1_translation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c9f52fd0-b32e-4d78-bf7d-eabe420dd72b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct1_df.to_csv(CT1_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8087ea21-5759-4557-92e5-3fd715e1fc9c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 7. Translate all Context Tier 2 Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2cc47fcf-018d-4b9a-b089-09ff68b0392a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3385"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct2_df = ct1_df[ct1_df.context_tier == \"Tier 2\"]\n",
    "ct2_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80bf9a45-4f90-4bf3-b3f5-5ac60e890c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_aya_ct2_prompt(row, G, ref_df):\n",
    "    sctid, language = row.Index\n",
    "    concept = G.get_full_concept(sctid)\n",
    "    preferred_term = concept.fsn.replace(f\"({concept.hierarchy})\", \"\").strip()\n",
    "    parent_concepts = [\n",
    "        G.get_full_concept(p.sctid) for p in concept.parents\n",
    "    ]\n",
    "    parent_data = [\n",
    "        (\n",
    "            c.fsn.replace(f\"({c.hierarchy})\", \"\").strip(),\n",
    "            ref_df.loc[(c.sctid, language)].reference_translations[0],\n",
    "        )\n",
    "        for c in parent_concepts\n",
    "    ] \n",
    "    related_concepts = [\n",
    "        G.get_full_concept(r.tgt.sctid)\n",
    "        for g in concept.inferred_relationship_groups\n",
    "        for r in g.relationships\n",
    "        if r.type in important_attributes        \n",
    "    ]    \n",
    "    relationship_data = [\n",
    "        (\n",
    "            c.fsn.replace(f\"({c.hierarchy})\", \"\").strip(),\n",
    "            ref_df.loc[(c.sctid, language)].reference_translations[0],\n",
    "        )\n",
    "        for c in related_concepts\n",
    "    ]\n",
    "    prompt_fragments = [\n",
    "        f'Translate the following clinical concept into {language}: \"{pt}\". {rt}.'\n",
    "        for pt, rt in chain(parent_data, relationship_data)\n",
    "    ]\n",
    "    prompt = '\\n'.join(prompt_fragments)\n",
    "    prompt += f'\\nTranslate the following clinical concept into {language}: \"{preferred_term}\". '\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2a2c580c-faa4-4168-b0bf-0dfdc4d1e778",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following clinical concept into Swedish: \"Finding related to ability to use language\". fynd relaterat till förmågan att använda språk.\n",
      "Translate the following clinical concept into Swedish: \"Does use verbal communication\". kommunicerar verbalt.\n",
      "Translate the following clinical concept into Swedish: \"Ability to use language\". förmåga att använda språket.\n",
      "Translate the following clinical concept into Swedish: \"Does use language\". \n"
     ]
    }
   ],
   "source": [
    "print(prepare_aya_ct2_prompt(next(ct2_df.sample(1).itertuples()), G, ref_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8e2598da-428b-42f3-a0aa-29e62ce9cc08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa4eae54cca4c498e0208f27d8efb82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_792/2093963965.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ct2_df[\"aya_ct2_translation\"] = list(translate_with_aya(ct2_df, G, prepare_aya_ct2_prompt, ref_df, None, rebuild=True, save=False))\n"
     ]
    }
   ],
   "source": [
    "ct2_df[\"aya_ct2_translation\"] = list(translate_with_aya(\n",
    "    ct2_df, G, prepare_aya_ct2_prompt, ref_df, None, rebuild=True, save=False\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd53efdd-b601-4c26-9a66-6553285688ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_translations(ct2_df, \"aya_ct2_translation\", ignore_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5de087d7-1e1b-4f53-b534-09f5f10199bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct2_df.to_csv(CT2_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a6ce754-f3ac-458d-bc85-2d7bd87e9ede",
   "metadata": {},
   "source": [
    "# 8. Enhancing RAG with ngram lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad729c6d-9fc4-4735-9cd6-b7c1d4e60cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def generate_similarity_search_keys(df):\n",
    "    languages = df.index.get_level_values(1).unique()\n",
    "    keys = dict()\n",
    "    for l in languages:\n",
    "        docs = [\n",
    "            (row.Index[0], row.fsn.replace(f\"({row.hierarchy})\", \"\").strip())\n",
    "            for row in df[df.index.get_level_values(1) == l].itertuples()\n",
    "        ]\n",
    "        values, terms = list(zip(*docs))\n",
    "        vectorizer = CountVectorizer(lowercase=True, stop_words=None, ngram_range=(2,10), binary=True)\n",
    "        key_matrix = vectorizer.fit_transform(terms)\n",
    "        keys[l] = (vectorizer, key_matrix, values)\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3d74a69-0b7b-48a0-8219-326991e3f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = generate_similarity_search_keys(ref_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aca58f10-4f59-4894-98b7-f9d6c2096aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar(keys, row, G, ref_df, k=3, min_score=2, remove_children=True):\n",
    "    sctid = row.Index[0]\n",
    "    language = row.Index[1]\n",
    "    vectorizer, key_matrix, values = keys[language]\n",
    "    term = row.fsn.replace(f\"({row.hierarchy})\", \"\").strip()\n",
    "    query = vectorizer.transform([term])\n",
    "    search = key_matrix.dot(query.T).A.ravel()\n",
    "    top_k = np.argpartition(-search, k+1)[0:k+1]\n",
    "    scores = search[top_k]\n",
    "    top_k = top_k[scores >= min_score]\n",
    "    results = set(np.array(values)[top_k])\n",
    "    if remove_children:\n",
    "        children = {c.sctid for c in G.get_descendants(sctid)}\n",
    "    else:\n",
    "        children = set()\n",
    "    results = results - {sctid} - children\n",
    "    if results != set():\n",
    "        concepts = [G.get_concept_details(r) for r in results]\n",
    "        preferred_terms = [c.fsn.replace(f\"({c.hierarchy})\", \"\").strip() for c in concepts]\n",
    "        reference_translations = [ref_df.loc[r, language].reference_translations[0] for r in results]\n",
    "        return list(zip(preferred_terms, reference_translations))\n",
    "    else:\n",
    "        return list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "48ad77d9-d87f-4922-98aa-028ea73e6e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match function signature for the other prompt compiling functions\n",
    "from functools import partial\n",
    "\n",
    "find_similar_ = partial(find_similar, keys=keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ae9b6c4b-8c22-473d-827a-b90b82896d34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bromide salt (substance)\n",
      "[]\n",
      "\n",
      "\n",
      "Finding of food and drink intake (finding)\n",
      "[('Food and drink intake', 'intake van voedsel en drinken'), ('Recommendation to change food and drink intake', 'aanbevelen om inname van eten en drinken aan te passen'), ('Positioning subject for food and drink intake', 'zorgafnemer in houding voor intake van voedsel en drinken plaatsen')]\n",
      "\n",
      "\n",
      "Prothrombin time within target range (finding)\n",
      "[]\n",
      "\n",
      "\n",
      "Mixed nerve conduction study (procedure)\n",
      "[('Sensory nerve conduction study', 'sensibel geleidingsonderzoek'), ('Nerve conduction study', 'zenuwgeleidingsonderzoek'), ('Finding of mixed nerve conduction pattern', 'bevinding betreffende geleidingspatroon van gemengde zenuw')]\n",
      "\n",
      "\n",
      "Intercondylar T/Y fracture (morphologic abnormality)\n",
      "[]\n",
      "\n",
      "\n",
      "Malignant tumor, small cell type (morphologic abnormality)\n",
      "[('Malignant tumor, giant cell type', 'grootcellige maligne tumor'), ('Malignant tumor, fusiform cell type', 'spoelcellige maligne tumor'), ('Malignant tumor, clear cell type', \"maligne neoplasma van 'clear cell'-type\")]\n",
      "\n",
      "\n",
      "Does not run down steps (finding)\n",
      "[('Does not run down stairs', 'rent trap niet af'), ('Does not run down a slope', 'rent niet van helling af'), ('Does not run down hill', 'rent niet van heuvel af')]\n",
      "\n",
      "\n",
      "Ethylenediamine dihydrochloride (substance)\n",
      "[]\n",
      "\n",
      "\n",
      "Under care of school nurse (finding)\n",
      "[('Under care of surgeon', 'onder behandeling van chirurg'), ('Under care of public health physician', 'onder behandeling van arts maatschappij en gezondheid'), ('Under care of breast surgeon', 'onder behandeling van mammachirurg')]\n",
      "\n",
      "\n",
      "Fleurette (morphologic abnormality)\n",
      "[]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for row in all_df[all_df.index.get_level_values(1) == \"Dutch\"].sample(10).itertuples():\n",
    "    print(row.fsn)\n",
    "    print(find_similar_(row=row, G=G, ref_df=ref_df))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "41ba6131-f264-4ab3-94a0-2fefd9b31fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dutch</td>\n",
       "      <td>1901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Estonian</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Korean</td>\n",
       "      <td>1085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Swedish</td>\n",
       "      <td>1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   language   cnt\n",
       "0     Dutch  1901\n",
       "1  Estonian   878\n",
       "2    Korean  1085\n",
       "3   Swedish  1925"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# sim_df = deepcopy(all_df)\n",
    "\n",
    "# sim_df[\"similarity_tier\"] = [\n",
    "#     \"Tier 1\" if find_similar(row, G, keys, ref_df) != [] else \"All Translations\" \n",
    "#     for row in tqdm(sim_df.itertuples(), total=sim_df.shape[0])\n",
    "# ]\n",
    "\n",
    "sim_df = sim_df[sim_df.similarity_tier == \"Tier 1\"]\n",
    "\n",
    "(\n",
    "    sim_df\n",
    "    .reset_index()\n",
    "    .groupby([\"language\"])\n",
    "    .size()\n",
    "    .rename(\"cnt\")\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547b2227-4a19-46d0-a6f5-190fd6fa8ac6",
   "metadata": {},
   "source": [
    "## Translations using similarity results only (no context tier augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50710768-403b-4304-b79a-265ca3da83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_aya_similarity_prompt(row, G, ref_df):\n",
    "    sctid, language = row.Index\n",
    "    concept = G.get_full_concept(sctid)\n",
    "    preferred_term = concept.fsn.replace(f\"({concept.hierarchy})\", \"\").strip()\n",
    "    results = find_similar_(row=row, G=G, ref_df=ref_df)\n",
    "    prompt_fragments = [\n",
    "        f'Translate the following clinical concept into {language}: \"{pt}\". {rt}.'\n",
    "        for pt, rt in results\n",
    "    ]\n",
    "    prompt = '\\n'.join(prompt_fragments)\n",
    "    prompt += f'\\nTranslate the following clinical concept into {language}: \"{preferred_term}\". '\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "077e0127-02e1-4445-98c5-a55d84eb4d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following clinical concept into Swedish: \"Biopsy of joint structure of shoulder\". biopsi från ledstruktur i axel.\n",
      "Translate the following clinical concept into Swedish: \"Excisional biopsy of joint structure of shoulder\". excisionsbiopsi från ledstruktur i axel.\n",
      "Translate the following clinical concept into Swedish: \"Percutaneous fine needle aspiration biopsy of joint structure of shoulder using imaging guidance\". bildvägledd perkutan finnålsbiopsi från axelled.\n",
      "Translate the following clinical concept into Swedish: \"Joint structure of shoulder region\". \n"
     ]
    }
   ],
   "source": [
    "print(prepare_aya_similarity_prompt(next(sim_df.sample(1).itertuples()), G, ref_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "635f4fbf-1c04-467e-b31c-a10ab4bf97c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ad02900396443492ca9eadb1e00c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5789 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 13\u001b[0m, in \u001b[0;36mtranslate_with_aya\u001b[0;34m(df, G, prompt_assembler, ref_df, results_filepath, rebuild, save)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '713278001_Estonian'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sim_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maya_similarity_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtranslate_with_aya\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43msim_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepare_aya_similarity_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrebuild\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 17\u001b[0m, in \u001b[0;36mtranslate_with_aya\u001b[0;34m(df, G, prompt_assembler, ref_df, results_filepath, rebuild, save)\u001b[0m\n\u001b[1;32m     15\u001b[0m prompt \u001b[38;5;241m=\u001b[39m prompt_assembler(row, G, ref_df)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mencode(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43maya_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m result \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(output[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     19\u001b[0m result \u001b[38;5;241m=\u001b[39m aya_postprocessor(result)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/generation/utils.py:1718\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1701\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massisted_decoding(\n\u001b[1;32m   1702\u001b[0m         input_ids,\n\u001b[1;32m   1703\u001b[0m         assistant_model\u001b[38;5;241m=\u001b[39massistant_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1714\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1715\u001b[0m     )\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGREEDY_SEARCH:\n\u001b[1;32m   1717\u001b[0m     \u001b[38;5;66;03m# 11. run greedy search\u001b[39;00m\n\u001b[0;32m-> 1718\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgreedy_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1724\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1725\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1726\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1727\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1728\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1729\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mCONTRASTIVE_SEARCH:\n\u001b[1;32m   1732\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/generation/utils.py:2579\u001b[0m, in \u001b[0;36mGenerationMixin.greedy_search\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   2576\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2578\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2579\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2580\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2581\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2582\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2583\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2587\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1743\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1740\u001b[0m         decoder_attention_mask \u001b[38;5;241m=\u001b[39m decoder_attention_mask\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfirst_device)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# Decode\u001b[39;00m\n\u001b[0;32m-> 1743\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1758\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m decoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1760\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1110\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m   1096\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39mforward,\n\u001b[1;32m   1097\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         output_attentions,\n\u001b[1;32m   1108\u001b[0m     )\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1110\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_decoder_position_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_layer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1121\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;66;03m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:694\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m hidden_states, present_key_value_state \u001b[38;5;241m=\u001b[39m self_attention_outputs[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    704\u001b[0m attention_outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m2\u001b[39m:]  \u001b[38;5;66;03m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:600\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    592\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    598\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    599\u001b[0m ):\n\u001b[0;32m--> 600\u001b[0m     normed_hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mSelfAttention(\n\u001b[1;32m    602\u001b[0m         normed_hidden_states,\n\u001b[1;32m    603\u001b[0m         mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    608\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    609\u001b[0m     )\n\u001b[1;32m    610\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(attention_output[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/accelerate/hooks.py:165\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/venvs/snomed/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:253\u001b[0m, in \u001b[0;36mT5LayerNorm.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states):\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# T5 uses a layer_norm which only scales and doesn't shift, which is also known as Root Mean\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# Square Layer Normalization https://arxiv.org/abs/1910.07467 thus varience is calculated\u001b[39;00m\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# w/o mean and there is no bias. Additionally we want to make sure that the accumulation for\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;66;03m# half-precision inputs is done in fp32\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m     variance \u001b[38;5;241m=\u001b[39m \u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m hidden_states \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mrsqrt(variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariance_epsilon)\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# convert into half-precision if necessary\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sim_df[\"aya_similarity_translation\"] = list(translate_with_aya(\n",
    "    sim_df, G, prepare_aya_similarity_prompt, ref_df, None, rebuild=True, save=False\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8c3bb79c-760b-4a1d-a828-769216fb80f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.1967503692762186,\n",
       " 'levenshtein_ratio': 0.08223037944555804,\n",
       " 'google_bleu': 0.06679764243614932,\n",
       " 'cer_score': 0.6876011922594623}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_translations(ct2_df, \"deepl_translation\", ignore_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f2c945c-b63a-4b22-8a65-f7b8354d0869",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.08980797636632201,\n",
       " 'levenshtein_ratio': 0.08760223122820525,\n",
       " 'google_bleu': 0.04098139660285791,\n",
       " 'cer_score': 0.7679424916650236}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_translations(ct2_df, \"aya_vanilla_translation\", ignore_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67e82db9-e9e4-4dbc-a5c4-864fd04baaac",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# evaluate_translations(ct2_df, \"aya_ct1_translation\", ignore_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "19fb3084-ef7f-4155-8317-05298464c509",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'exact_match': 0.2838995568685377,\n",
       " 'levenshtein_ratio': 0.08972250166950493,\n",
       " 'google_bleu': 0.08574728824877723,\n",
       " 'cer_score': 0.6900741462809425}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_translations(ct2_df, \"aya_ct2_translation\", ignore_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d5c9e2e5-1126-4b3f-a7c2-94472352f22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.to_csv(SIM_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61c9955-c731-4c10-83b9-19b0ae5d757a",
   "metadata": {},
   "source": [
    "# 9. SFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d11d4-2bd2-4836-87d4-796491e742a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 9.1 Generate fine-tuning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2292e3fc-e2fa-4048-8d9a-530d340ec14a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def generate_sft_prompt(example):\n",
    "    preferred_term = example[\"fsn\"].replace(f\"({example['hierarchy']})\", \"\").strip()\n",
    "    prompt = f\"Translate into {example['language']}: {preferred_term}.\"\n",
    "    return {\"prompt\": prompt}\n",
    "    \n",
    "dataset = Dataset.from_pandas(all_df)\n",
    "dataset = dataset.map(generate_sft_prompt)\n",
    "dataset = dataset.train_test_split(test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626363f-da58-431b-b846-a72b8be1f465",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c717de94-56dc-43ff-8202-04bccb2075d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=aya_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "99b1bd6e-803d-47ed-b160-6fa72586ac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoraConfig \"task_type\" parameter seems to have been deprecated\n",
    "# LoraConfig \"target_modules\" parameter currently not specified\n",
    "# Currently performing full precision training (no use of prepare_model_for_kbit_training)\n",
    "# LoRA r-rate, alpha and dropout taken from: https://github.com/georgian-io/LLM-Finetuning-Hub (see script params in README)\n",
    "\n",
    "from peft import LoraConfig, PeftModel\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    r=16,\n",
    "    bias=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32b5c26-dcbe-4a52-a15b-d746c15f09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    report_to=\"wandb\",\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=aya_model,\n",
    "    args=training_args,\n",
    "    peft_config=peft_config,\n",
    "    # train_dataset=tokenized_books[\"train\"],\n",
    "    # eval_dataset=tokenized_books[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a40e17-a184-4470-b4a2-f07de4d7fb1b",
   "metadata": {},
   "source": [
    "# 10. Final Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb2d835d-e5c8-4c66-8ea2-1662bd63b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.read_csv(ALL_OUTPUT_PATH).set_index([\"sctid\", \"language\"])\n",
    "ct1_df = pd.read_csv(CT1_OUTPUT_PATH).set_index([\"sctid\", \"language\"])\n",
    "ct2_df = pd.read_csv(CT2_OUTPUT_PATH).set_index([\"sctid\", \"language\"])\n",
    "sim_df = pd.read_csv(SIM_OUTPUT_PATH).set_index([\"sctid\", \"language\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bbd0e6-bad0-4382-a7d4-f217e73f6cbe",
   "metadata": {},
   "source": [
    "## 10.1 Sampling Translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c40afcb0-189f-4046-80ee-a3b913909a3e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 298777007 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Swedish \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Increased active range of shoulder flexion \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['ökat rörelseomfång i skuldra vid aktiv flexion'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Ökat aktivt omfång av axelflexion \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.05882352941176472, google_bleu: 0.0, cer_score: 0.8181818181818182 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Ökat aktivt skulderflexionsintervall \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.05405405405405406, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m Ökat rörelseomfång vid aktiv flexion i axelled \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.04255319148936165, google_bleu: 0.16666666666666666, cer_score: 0.45652173913043476 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m Ökat rörelseomfång vid aktiv flexion i axelled \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.04255319148936165, google_bleu: 0.16666666666666666, cer_score: 0.45652173913043476\n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 449723004 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Estonian \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Absolute hypermetropia \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Absoluutne hüperoopia'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Absoluutne hüpermetroopia \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.07692307692307687, google_bleu: 0.0, cer_score: 0.32 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Absoluutne hüpermetroopia \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.07692307692307687, google_bleu: 0.0, cer_score: 0.32 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m Absoluutne hüperoopia \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 1.0, levenshtein_ratio: 0.09090909090909094, google_bleu: 0.0, cer_score: 0.19047619047619047 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m Absoluutne hüperoopia \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 1.0, levenshtein_ratio: 0.09090909090909094, google_bleu: 0.0, cer_score: 0.19047619047619047\n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 230393000 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Estonian \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Lateral temporal epilepsy \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['Lateraalse oimusagara epilepsia', 'Lateraalse temporaalsagara epilepsia'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Lateraalne temporaalne epilepsia \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.06060606060606055, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Lateraalne temporal epileps \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.0714285714285714, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m Lateraalne temporalis epilepsia \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.0625, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m Lateraalne oimusagar \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.09523809523809523, google_bleu: 0.0, cer_score: 1.0\n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 11816021000119102 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Dutch \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Injury of left brachial artery \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['letsel van linker arteria brachialis', 'letsel van slagader van linker bovenarm', 'letsel van arteria brachialis sinistra'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Verwonding van linker arteria brachialis \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.04878048780487809, google_bleu: 0.10810810810810811, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Gewonde linkerbrachiale aderen \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.06451612903225812, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m letsel van de linker brachiale arterie \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.05128205128205132, google_bleu: 0.02702702702702703, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m letsel van linker arteria brachialis \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 1.0, levenshtein_ratio: 0.05405405405405406, google_bleu: 0.10810810810810811, cer_score: 1.0\n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 301000005 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Swedish \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Left basal pneumonia \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['pneumoni i vänster nedre lob'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Lunginflammation i vänster nedre zon \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.05405405405405406, google_bleu: 0.2727272727272727, cer_score: 0.4722222222222222 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Left lower zone pneumonia \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.07692307692307687, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m Basal lunginflammation \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.08695652173913049, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m vänster nedre zon pneumoni \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.07407407407407407, google_bleu: 0.13636363636363635, cer_score: 0.6923076923076923\n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 308439003 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Swedish \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Referral to midwife \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['remittering till barnmorska'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Hänvisning till barnmorska \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.07407407407407407, google_bleu: 0.07142857142857142, cer_score: 0.4230769230769231 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Referens till barnmorska \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.07999999999999996, google_bleu: 0.07142857142857142, cer_score: 0.4166666666666667 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m remittering till barnmorska \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 1.0, levenshtein_ratio: 0.0714285714285714, google_bleu: 0.07142857142857142, cer_score: 0.14814814814814814 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m remittering till barnmorska \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 1.0, levenshtein_ratio: 0.0714285714285714, google_bleu: 0.07142857142857142, cer_score: 0.14814814814814814\n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 95940008 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Swedish \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Soft tissues of hip \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['mjukdelar i höft, struktur'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Struktur av mjukdelar i höften \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.06451612903225812, google_bleu: 0.045454545454545456, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Struktur av mjuka vävnader i knä \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.06060606060606055, google_bleu: 0.045454545454545456, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m höft, mjukdelar \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.125, google_bleu: 0.13636363636363635, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m höft, struktur \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 1.0, levenshtein_ratio: 0.1333333333333333, google_bleu: 0.13636363636363635, cer_score: 1.0\n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 181031003 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Dutch \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Ulnar nerve, dorsal sensory branch \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['structuur van dorsale sensorische tak van nervus ulnaris', 'ramus dorsalis van nervus ulnaris', 'structuur van ramus dorsalis van nervus ulnaris'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Structuur van de dorsale sensibele tak van de nervus ulnaris \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.032786885245901676, google_bleu: 0.06666666666666667, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Structuur van de dorsale sensorische tak van de ulnaire zenuw \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.032258064516129004, google_bleu: 0.12222222222222222, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m Ulna, dorsale sensorische tak \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.06666666666666665, google_bleu: 0.07777777777777778, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m structuur van de dorsale sensibele tak van de ulnaire zenuw \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.033333333333333326, google_bleu: 0.05555555555555555, cer_score: 1.0\n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 20516002 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Dutch \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Spinal cordotomy \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['spinale chordotomie', 'chordotomie'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Ruggenmerg cordotomie \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.09090909090909094, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Spinale cordotomie \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.10526315789473684, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m Spinale cordotomie \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.10526315789473684, google_bleu: 0.0, cer_score: 1.0 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m spinale cordotomie \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.10526315789473684, google_bleu: 0.0, cer_score: 1.0\n",
      "\u001b[1m\u001b[31m\n",
      "SCTID: \u001b[0m 395950006 \u001b[1m\u001b[31m\n",
      "Target Language: \u001b[0m Dutch \u001b[1m\u001b[31m\n",
      "English Preferred Term: \u001b[0m Sodium chondroitin sulphate \u001b[1m\u001b[31m\n",
      "Reference Translations: \u001b[0m ['natriumchondroïtinesulfaat'] \u001b[1m\u001b[31m\n",
      "DeepL Translation: \u001b[0m Natriumchondroïtinesulfaat \u001b[1m\u001b[31m\n",
      "DeepL Scores: \u001b[0m exact_match: 1.0, levenshtein_ratio: 0.07407407407407407, google_bleu: 0.0, cer_score: 0.15384615384615385 \u001b[1m\u001b[31m\n",
      "Vanilla Aya Translation: \u001b[0m Sodium chondroïtinesulfaat \u001b[1m\u001b[31m\n",
      "Vanilla Aya Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.07407407407407407, google_bleu: 0.0, cer_score: 0.34615384615384615 \u001b[1m\u001b[31m\n",
      "Aya CT1 Translation: \u001b[0m chondroïtinesulfaat \u001b[1m\u001b[31m\n",
      "Aya CT1 Scores: \u001b[0m exact_match: 1.0, levenshtein_ratio: 0.09999999999999998, google_bleu: 0.0, cer_score: 0.5789473684210527 \u001b[1m\u001b[31m\n",
      "Aya CT2 Translation: \u001b[0m chondroïtinesulfaat natrium \u001b[1m\u001b[31m\n",
      "Aya CT2 Scores: \u001b[0m exact_match: 0.0, levenshtein_ratio: 0.0714285714285714, google_bleu: 0.0, cer_score: 0.6296296296296297\n"
     ]
    }
   ],
   "source": [
    "for row in ct2_df.sample(10).itertuples():\n",
    "    sctid, language = row.Index\n",
    "    preferred_term = G.get_concept_details(sctid).synonyms[0]\n",
    "    deepl_results = evaluate_translations(row, \"deepl_translation\", ignore_case=ignore_case)\n",
    "    vanilla_aya_results = evaluate_translations(row, \"aya_vanilla_translation\", ignore_case=ignore_case)\n",
    "    ct1_aya_results = evaluate_translations(row, \"aya_ct1_translation\", ignore_case=ignore_case)\n",
    "    ct2_aya_results = evaluate_translations(row, \"aya_ct2_translation\", ignore_case=ignore_case)\n",
    "    print(\n",
    "        colored(\"\\nSCTID: \", \"red\", attrs=['bold']),\n",
    "        sctid,\n",
    "        colored(\"\\nTarget Language: \", \"red\", attrs=['bold']),\n",
    "        language,\n",
    "        colored(\"\\nEnglish Preferred Term: \", \"red\", attrs=['bold']),\n",
    "        preferred_term,\n",
    "        colored(\"\\nReference Translations: \", \"red\", attrs=['bold']),\n",
    "        row.reference_translations,\n",
    "        colored(\"\\nDeepL Translation: \", \"red\", attrs=['bold']),\n",
    "        row.deepl_translation,\n",
    "        colored(\"\\nDeepL Scores: \", \"red\", attrs=['bold']),\n",
    "        \", \".join([k+\": \"+str(v) for k,v in deepl_results.items()]),\n",
    "        colored(\"\\nVanilla Aya Translation: \", \"red\", attrs=['bold']),\n",
    "        row.aya_vanilla_translation,\n",
    "        colored(\"\\nVanilla Aya Scores: \", \"red\", attrs=['bold']),\n",
    "        \", \".join([k+\": \"+str(v) for k,v in vanilla_aya_results.items()]),        \n",
    "        colored(\"\\nAya CT1 Translation: \", \"red\", attrs=['bold']),\n",
    "        row.aya_ct1_translation,\n",
    "        colored(\"\\nAya CT1 Scores: \", \"red\", attrs=['bold']),\n",
    "        \", \".join([k+\": \"+str(v) for k,v in ct1_aya_results.items()]),          \n",
    "        colored(\"\\nAya CT2 Translation: \", \"red\", attrs=['bold']),\n",
    "        row.aya_ct2_translation,\n",
    "        colored(\"\\nAya CT2 Scores: \", \"red\", attrs=['bold']),\n",
    "        \", \".join([k+\": \"+str(v) for k,v in ct2_aya_results.items()]),                  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dab2bdad-46b4-4355-8888-c98d86ce6b98",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prepare_aya_ct2_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(ct2_df[ct2_df\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_level_values(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m449723004\u001b[39m]\u001b[38;5;241m.\u001b[39mitertuples())\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mprepare_aya_ct2_prompt\u001b[49m(row, G, ref_df))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prepare_aya_ct2_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "row = next(ct2_df[ct2_df.index.get_level_values(0) == 449723004].itertuples())\n",
    "print(prepare_aya_ct2_prompt(row, G, ref_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f661dc-7624-47e7-bddc-e9ed7cfd8659",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
